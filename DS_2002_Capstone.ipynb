{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42797d08-4a38-4cfc-bd04-554eca9abbe9",
   "metadata": {},
   "source": [
    "# DS 2002 Final Project/Capstone\n",
    "## Using Juptyer Notebook integrate adventureWorks sample data into Pyspark Environment\n",
    "## Data: Adventure Works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a2a506-b180-4ccc-9d1e-0aa33e9889ff",
   "metadata": {},
   "source": [
    "#### Directions/Objectives\n",
    "1. The Date dimension, and one other dimension of your choosing must be extracted from the MySQL adventureworks database.\n",
    "2. Data from at least one other dimension must be exported from the MySQL adventureworks database as a JSON file, which must then be uploaded to MongoDB to create a new database/collection.  Your final project notebook must then extract the data from that MongoDB database/collection to create a new dimension in your data lakehouse.\n",
    "3. Data from one at least one other dimension must be exported from the MySQL adventureworks database as a CSV file, which must then be read from your local hard disk to create a new dimension in your data lakehouse.\n",
    "4. Data from your Fact Table must be exported from the MySQL adventureworks database into at least three (3) separate JSON files, which will then be read into a series of PySpark Streaming Dataframes (e.g., Bronze, Silver and Gold) to complete the Lambda architecture of your Data Lakehouse. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e249cfb-f07e-4abc-abaf-200c7bc6091c",
   "metadata": {},
   "source": [
    "## Section I: Prerequisites\n",
    "\n",
    "### 1.0. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd08f63-40e8-4864-8cee-57bcc3d2cf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\spark-3.5.4-bin-hadoop3\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print(findspark.find())\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pymongo\n",
    "import certifi\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window as W\n",
    "\n",
    "import numpy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9692884f-6cbb-4c39-a22d-8575bae5aafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SQL Alchemy Version: 2.0.37\n",
      "Running PyMongo Version: 4.11.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running SQL Alchemy Version: {sqlalchemy.__version__}\")\n",
    "print(f\"Running PyMongo Version: {pymongo.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4518d9-d6c5-4216-a591-540514541b66",
   "metadata": {},
   "source": [
    "### 2.0. Instantiate Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed1f051-b7cd-48f2-81a4-074ca48e9058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Specify MySQL Server Connection Information\n",
    "# --------------------------------------------------------------------------------\n",
    "uid = \"BryanTang\"\n",
    "pwd = \"pAssword123\"\n",
    "hostname = \"localhost\"\n",
    "dbname = \"adventureworks\"\n",
    "src_dbname = \"adventureworks\"\n",
    "dst_dbname = \"adventureworks_dw\"\n",
    "\n",
    "mysql_args = {\n",
    "    \"host_name\": \"localhost\",\n",
    "    \"port\": \"3306\",\n",
    "    \"db_name\": \"adventureworks\",         # Overwrite with the intended db\n",
    "    \"src_dbname\": \"adventureworks\",      # Added from first block\n",
    "    \"dst_dbname\": \"adventureworks_dw\",   # Added from first block\n",
    "    \"conn_props\": {\n",
    "        \"user\": \"BryanTang\",\n",
    "        \"password\": \"pAssword123\",\n",
    "        \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Specify MongoDB Cluster Connection Information\n",
    "# --------------------------------------------------------------------------------\n",
    "mongodb_args = {\n",
    "    \"cluster_location\" : \"atlas\", # \"atlas\"\n",
    "    \"user_name\" : \"tangbryan8\",\n",
    "    \"password\" : \"bryan817510\",\n",
    "    \"cluster_name\" : \"sandbox\",\n",
    "    \"cluster_subnet\" : \"zdqab\",\n",
    "    \"db_name\" : \"adventureworks\",\n",
    "    \"collection\" : \"\",\n",
    "    \"null_column_threshold\" : 0.5\n",
    "}\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Specify Directory Structure for Source Data\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "base_dir = os.path.join(os.getcwd(), 'proj_data')\n",
    "data_dir = os.path.join(base_dir, 'adventureworks')\n",
    "batch_dir = os.path.join(data_dir, 'batch')\n",
    "stream_dir = os.path.join(data_dir, 'streaming')\n",
    "\n",
    "fact_orders_stream_dir = os.path.join(stream_dir, 'fact_orders')\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Create Directory Structure for Data Lakehouse Files\n",
    "# --------------------------------------------------------------------------------\n",
    "dest_database = \"adventureworks_dlh\"\n",
    "sql_warehouse_dir = os.path.abspath('spark-warehouse')\n",
    "dest_database_dir = f\"{dest_database}.db\"\n",
    "database_dir = os.path.join(sql_warehouse_dir, dest_database_dir)\n",
    "\n",
    "fact_orders_output_bronze = os.path.join(database_dir, 'fact_orders', 'bronze')\n",
    "fact_orders_output_silver = os.path.join(database_dir, 'fact_orders', 'silver')\n",
    "fact_orders_output_gold = os.path.join(database_dir, 'fact_orders', 'gold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64185a80-43cc-4f66-ae67-d7a6659a6e03",
   "metadata": {},
   "source": [
    "### 3.0. Define Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf9c8d1e-e9cd-45eb-a32f-61b71c820109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_info(path: str):\n",
    "    file_sizes = []\n",
    "    modification_times = []\n",
    "\n",
    "    '''Fetch each item in the directory, and filter out any directories.'''\n",
    "    items = os.listdir(path)\n",
    "    files = sorted([item for item in items if os.path.isfile(os.path.join(path, item))])\n",
    "\n",
    "    '''Populate lists with the Size and Last Modification DateTime for each file in the directory.'''\n",
    "    for file in files:\n",
    "        file_sizes.append(os.path.getsize(os.path.join(path, file)))\n",
    "        modification_times.append(pd.to_datetime(os.path.getmtime(os.path.join(path, file)), unit='s'))\n",
    "\n",
    "    data = list(zip(files, file_sizes, modification_times))\n",
    "    column_names = ['name','size','modification_time']\n",
    "    \n",
    "    return pd.DataFrame(data=data, columns=column_names)\n",
    "\n",
    "\n",
    "def wait_until_stream_is_ready(query, min_batches=1):\n",
    "    while len(query.recentProgress) < min_batches:\n",
    "        time.sleep(5)\n",
    "        \n",
    "    print(f\"The stream has processed {len(query.recentProgress)} batchs\")\n",
    "\n",
    "\n",
    "def remove_directory_tree(path: str):\n",
    "    '''If it exists, remove the entire contents of a directory structure at a given 'path' parameter's location.'''\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "            return f\"Directory '{path}' has been removed successfully.\"\n",
    "        else:\n",
    "            return f\"Directory '{path}' does not exist.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "        \n",
    "\n",
    "def drop_null_columns(df, threshold):\n",
    "    '''Drop Columns having a percentage of NULL values that exceeds the given 'threshold' parameter value.'''\n",
    "    columns_with_nulls = [col for col in df.columns if df.filter(df[col].isNull()).count() / df.count() > threshold] \n",
    "    df_dropped = df.drop(*columns_with_nulls) \n",
    "    \n",
    "    return df_dropped\n",
    "    \n",
    "    \n",
    "def get_mysql_dataframe(spark_session, sql_query : str, **args):\n",
    "    '''Create a JDBC URL to the MySQL Database'''\n",
    "    jdbc_url = f\"jdbc:mysql://{args['host_name']}:{args['port']}/{args['db_name']}\"\n",
    "    \n",
    "    '''Invoke the spark.read.format(\"jdbc\") function to query the database, and fill a DataFrame.'''\n",
    "    dframe = spark_session.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"driver\", args['conn_props']['driver']) \\\n",
    "    .option(\"user\", args['conn_props']['user']) \\\n",
    "    .option(\"password\", args['conn_props']['password']) \\\n",
    "    .option(\"query\", sql_query) \\\n",
    "    .load()\n",
    "    \n",
    "    return dframe\n",
    "    \n",
    "\n",
    "def get_mongo_uri(**args):\n",
    "    '''Validate proper input'''\n",
    "    if args[\"cluster_location\"] not in ['atlas', 'local']:\n",
    "        raise Exception(\"You must specify either 'atlas' or 'local' for the 'cluster_location' parameter.\")\n",
    "        \n",
    "    if args['cluster_location'] == \"atlas\":\n",
    "        uri = f\"mongodb+srv://{args['user_name']}:{args['password']}@\"\n",
    "        uri += f\"{args['cluster_name']}.{args['cluster_subnet']}.mongodb.net/\"\n",
    "    else:\n",
    "        uri = \"mongodb://localhost:27017/\"\n",
    "\n",
    "    return uri\n",
    "\n",
    "\n",
    "def get_spark_conf_args(spark_jars : list, **args):\n",
    "    jars = \"\"\n",
    "    for jar in spark_jars:\n",
    "        jars += f\"{jar}, \"\n",
    "    \n",
    "    sparkConf_args = {\n",
    "        \"app_name\" : \"PySpark Northwind Data Lakehouse (Medallion Architecture)\",\n",
    "        \"worker_threads\" : f\"local[{int(os.cpu_count()/2)}]\",\n",
    "        \"shuffle_partitions\" : int(os.cpu_count()),\n",
    "        \"mongo_uri\" : get_mongo_uri(**args),\n",
    "        \"spark_jars\" : jars[0:-2],\n",
    "        \"database_dir\" : sql_warehouse_dir\n",
    "    }\n",
    "    \n",
    "    return sparkConf_args\n",
    "    \n",
    "\n",
    "def get_spark_conf(**args):\n",
    "    sparkConf = SparkConf().setAppName(args['app_name'])\\\n",
    "    .setMaster(args['worker_threads']) \\\n",
    "    .set('spark.driver.memory', '4g') \\\n",
    "    .set('spark.executor.memory', '2g') \\\n",
    "    .set('spark.jars', args['spark_jars']) \\\n",
    "    .set('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1') \\\n",
    "    .set('spark.mongodb.input.uri', args['mongo_uri']) \\\n",
    "    .set('spark.mongodb.output.uri', args['mongo_uri']) \\\n",
    "    .set('spark.sql.adaptive.enabled', 'false') \\\n",
    "    .set('spark.sql.debug.maxToStringFields', 35) \\\n",
    "    .set('spark.sql.shuffle.partitions', args['shuffle_partitions']) \\\n",
    "    .set('spark.sql.streaming.forceDeleteTempCheckpointLocation', 'true') \\\n",
    "    .set('spark.sql.streaming.schemaInference', 'true') \\\n",
    "    .set('spark.sql.warehouse.dir', args['database_dir']) \\\n",
    "    .set('spark.streaming.stopGracefullyOnShutdown', 'true')\n",
    "    \n",
    "    return sparkConf\n",
    "\n",
    "\n",
    "def get_mongo_client(**args):\n",
    "    '''Get MongoDB Client Connection'''\n",
    "    mongo_uri = get_mongo_uri(**args)\n",
    "    if args['cluster_location'] == \"atlas\":\n",
    "        client = pymongo.MongoClient(mongo_uri, tlsCAFile=certifi.where())\n",
    "\n",
    "    elif args['cluster_location'] == \"local\":\n",
    "        client = pymongo.MongoClient(mongo_uri)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"A MongoDB Client could not be created.\")\n",
    "\n",
    "    return client\n",
    "    \n",
    "    \n",
    "# TODO: Rewrite this to leverage PySpark?\n",
    "def set_mongo_collections(mongo_client, db_name : str, data_directory : str, json_files : list):\n",
    "    db = mongo_client[db_name]\n",
    "    \n",
    "    for file in json_files:\n",
    "        db.drop_collection(file)\n",
    "        json_file = os.path.join(data_directory, json_files[file])\n",
    "        with open(json_file, 'r') as openfile:\n",
    "            json_object = json.load(openfile)\n",
    "            file = db[file]\n",
    "            result = file.insert_many(json_object)\n",
    "        \n",
    "    mongo_client.close()\n",
    "    \n",
    "\n",
    "def get_mongodb_dataframe(spark_session, **args):\n",
    "    '''Query MongoDB, and create a DataFrame'''\n",
    "    dframe = spark_session.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "        .option(\"database\", args['db_name']) \\\n",
    "        .option(\"collection\", args['collection']).load()\n",
    "\n",
    "    '''Drop the '_id' index column to clean up the response.'''\n",
    "    dframe = dframe.drop('_id')\n",
    "    \n",
    "    '''Call the drop_null_columns() function passing in the dataframe.'''\n",
    "    dframe = drop_null_columns(dframe, args['null_column_threshold'])\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "def get_mongo_dataframe(mongo_client, db_name, collection, query):\n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = mongo_client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    mongo_client.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "    \n",
    "def get_sql_dataframe(sql_query, **args):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    host = args[\"host_name\"]\n",
    "    port = args.get(\"port\", \"3306\")\n",
    "    db = args[\"db_name\"]\n",
    "\n",
    "    conn_props = args[\"conn_props\"]\n",
    "    user = conn_props[\"user\"]\n",
    "    pwd = conn_props[\"password\"]\n",
    "\n",
    "    conn_str = f\"mysql+pymysql://{user}:{pwd}@{host}:{port}/{db}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    dframe = pd.read_sql(text(sql_query), connection)\n",
    "    connection.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "    \n",
    "\n",
    "def set_dataframe(df, table_name, pk_column, db_operation, **args):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{args['user']}:{args['password']}@{args['hostname']}/{args['dbname']}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        connection.execute(text(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\"))\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1d002-fb99-4629-bc2b-05db697427c7",
   "metadata": {},
   "source": [
    "### 4.0. Initialize Data Lakehouse Directory Structure\n",
    "Remove the Data Lakehouse Database Directory Structure to Ensure Idempotency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44474e15-d48c-4e43-9682-d7591bb4b684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Directory 'C:\\\\Users\\\\tangb\\\\DS-2002-main\\\\Projects\\\\spark-warehouse\\\\adventureworks_dlh.db' does not exist.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_directory_tree(database_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc44a26-d610-4ffc-986c-0eb8e5bfeec4",
   "metadata": {},
   "source": [
    "### 5.0. Create a New Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b0163da-3900-44e7-bb0c-bf533b9d2875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded JARs: C:\\Users\\tangb\\DS-2002-main\\Projects\\mysql-connector-j-9.1.0\\mysql-connector-j-9.1.0.jar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.16:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark Northwind Data Lakehouse (Medallion Architecture)</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x150692850a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_threads = f\"local[{int(os.cpu_count()/2)}]\"\n",
    "\n",
    "jars = []\n",
    "mysql_spark_jar = os.path.join(os.getcwd(), \"mysql-connector-j-9.1.0\", \"mysql-connector-j-9.1.0.jar\")\n",
    "mssql_spark_jar = os.path.join(os.getcwd(), \"sqljdbc_12.8\", \"enu\", \"jars\", \"mssql-jdbc-12.8.1.jre11.jar\")\n",
    "\n",
    "jars.append(mysql_spark_jar)\n",
    "#jars.append(mssql_spark_jar)\n",
    "\n",
    "sparkConf_args = get_spark_conf_args(jars, **mongodb_args)\n",
    "\n",
    "sparkConf_args[\"spark.master\"] = worker_threads\n",
    "sparkConf = get_spark_conf(**sparkConf_args)\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"OFF\")\n",
    "print(\"Loaded JARs:\", spark.sparkContext._conf.get(\"spark.jars\"))\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ab3d5-1ce9-4ac1-9c09-a07322e8fcc4",
   "metadata": {},
   "source": [
    "### 6.0. Create a New Metadata Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae70e8ad-d0b2-4848-a66e-ee3ec37c002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DROP DATABASE IF EXISTS {dest_database} CASCADE;\")\n",
    "\n",
    "sql_create_db = f\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS {dest_database}\n",
    "    COMMENT 'DS-2002 Lab 06 Database'\n",
    "    WITH DBPROPERTIES (contains_pii = true, purpose = 'DS-2002 Lab 6.0');\n",
    "\"\"\"\n",
    "spark.sql(sql_create_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad802f-0169-4a05-bcd8-c6f3abd99e2b",
   "metadata": {},
   "source": [
    "## Section II: Populate Dimensions by Ingesting \"Cold-path\" Reference Data \n",
    "### 1.0. Fetch Data from the File System\n",
    "#### 1.1. Verify the location of the source data files on the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20dca527-acd2-49d7-b54a-5c9788090f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>modification_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dim_products.csv</td>\n",
       "      <td>83024</td>\n",
       "      <td>2025-03-17 20:31:00.838961124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dim_vendors.json</td>\n",
       "      <td>39705</td>\n",
       "      <td>2025-03-17 19:39:53.109505415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name   size             modification_time\n",
       "0  dim_products.csv  83024 2025-03-17 20:31:00.838961124\n",
       "1  dim_vendors.json  39705 2025-03-17 19:39:53.109505415"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_info(batch_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae0a38b-fb0e-4bc2-be5c-a0c4c690efff",
   "metadata": {},
   "source": [
    "### 1.2 Extract Dataframe from MySQL Adventureworks\n",
    "- Dimdate\n",
    "- Employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fa1c5f0-c0d9-41b4-8920-60621837f30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|date_key| full_date|\n",
      "+--------+----------+\n",
      "|20000101|2000-01-01|\n",
      "|20000102|2000-01-02|\n",
      "+--------+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|            date_key|                 int|   NULL|\n",
      "|           full_date|                date|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|  adventureworks_dlh|       |\n",
      "|               Table|            dim_date|       |\n",
      "|        Created Time|Wed May 07 17:54:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "|          Created By|         Spark 3.5.4|       |\n",
      "|                Type|             MANAGED|       |\n",
      "|            Provider|             parquet|       |\n",
      "|            Location|file:/C:/Users/ta...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_key</th>\n",
       "      <th>full_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000101</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000102</td>\n",
       "      <td>2000-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_key   full_date\n",
       "0  20000101  2000-01-01\n",
       "1  20000102  2000-01-02"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_dim_date = \"SELECT date_key, full_date FROM adventureworks.dim_date\"\n",
    "df_dim_date = get_mysql_dataframe(spark, sql_dim_date, **mysql_args)\n",
    "df_dim_date.show(2)\n",
    "df_dim_date.write.saveAsTable(f\"{dest_database}.dim_date\", mode=\"overwrite\")\n",
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_date;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_date LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61369cf5-fb09-45bb-9903-df9116e42186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+---------+--------------------+---------+--------------------+-------------------+-------------+------+-------------------+------------+-------------+--------------+-----------+--------------------+-------------------+\n",
      "|EmployeeID|NationalIDNumber|ContactID|             LoginID|ManagerID|               Title|          BirthDate|MaritalStatus|Gender|           HireDate|SalariedFlag|VacationHours|SickLeaveHours|CurrentFlag|             rowguid|       ModifiedDate|\n",
      "+----------+----------------+---------+--------------------+---------+--------------------+-------------------+-------------+------+-------------------+------------+-------------+--------------+-----------+--------------------+-------------------+\n",
      "|         1|        14417807|     1209|adventure-works\\guy1|       16|Production Techni...|1972-05-15 00:00:00|            M|     M|1996-07-31 00:00:00|       false|           21|            30|       true|[4A D0 E1 AA 37 C...|2004-07-31 00:00:00|\n",
      "|         2|       253022876|     1030|adventure-works\\k...|        6| Marketing Assistant|1977-06-03 00:00:00|            S|     M|1997-02-26 00:00:00|       false|           42|            41|       true|[40 02 48 1B C0 9...|2004-07-31 00:00:00|\n",
      "+----------+----------------+---------+--------------------+---------+--------------------+-------------------+-------------+------+-------------------+------------+-------------+--------------+-----------+--------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+------------------+-------+\n",
      "|            col_name|         data_type|comment|\n",
      "+--------------------+------------------+-------+\n",
      "|          EmployeeID|               int|   NULL|\n",
      "|    NationalIDNumber|       varchar(15)|   NULL|\n",
      "|           ContactID|               int|   NULL|\n",
      "|             LoginID|      varchar(256)|   NULL|\n",
      "|           ManagerID|               int|   NULL|\n",
      "|               Title|       varchar(50)|   NULL|\n",
      "|           BirthDate|         timestamp|   NULL|\n",
      "|       MaritalStatus|        varchar(1)|   NULL|\n",
      "|              Gender|        varchar(1)|   NULL|\n",
      "|            HireDate|         timestamp|   NULL|\n",
      "|        SalariedFlag|           boolean|   NULL|\n",
      "|       VacationHours|               int|   NULL|\n",
      "|      SickLeaveHours|               int|   NULL|\n",
      "|         CurrentFlag|           boolean|   NULL|\n",
      "|             rowguid|            binary|   NULL|\n",
      "|        ModifiedDate|         timestamp|   NULL|\n",
      "|                    |                  |       |\n",
      "|# Detailed Table ...|                  |       |\n",
      "|             Catalog|     spark_catalog|       |\n",
      "|            Database|adventureworks_dlh|       |\n",
      "+--------------------+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>NationalIDNumber</th>\n",
       "      <th>ContactID</th>\n",
       "      <th>LoginID</th>\n",
       "      <th>ManagerID</th>\n",
       "      <th>Title</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HireDate</th>\n",
       "      <th>SalariedFlag</th>\n",
       "      <th>VacationHours</th>\n",
       "      <th>SickLeaveHours</th>\n",
       "      <th>CurrentFlag</th>\n",
       "      <th>rowguid</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14417807</td>\n",
       "      <td>1209</td>\n",
       "      <td>adventure-works\\guy1</td>\n",
       "      <td>16</td>\n",
       "      <td>Production Technician - WC60</td>\n",
       "      <td>1972-05-15</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1996-07-31</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>[74, 208, 225, 170, 55, 194, 116, 73, 180, 213...</td>\n",
       "      <td>2004-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>253022876</td>\n",
       "      <td>1030</td>\n",
       "      <td>adventure-works\\kevin0</td>\n",
       "      <td>6</td>\n",
       "      <td>Marketing Assistant</td>\n",
       "      <td>1977-06-03</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>1997-02-26</td>\n",
       "      <td>False</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>True</td>\n",
       "      <td>[64, 2, 72, 27, 192, 149, 15, 65, 167, 23, 235...</td>\n",
       "      <td>2004-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID NationalIDNumber  ContactID                 LoginID  ManagerID  \\\n",
       "0           1         14417807       1209    adventure-works\\guy1         16   \n",
       "1           2        253022876       1030  adventure-works\\kevin0          6   \n",
       "\n",
       "                          Title  BirthDate MaritalStatus Gender   HireDate  \\\n",
       "0  Production Technician - WC60 1972-05-15             M      M 1996-07-31   \n",
       "1           Marketing Assistant 1977-06-03             S      M 1997-02-26   \n",
       "\n",
       "   SalariedFlag  VacationHours  SickLeaveHours  CurrentFlag  \\\n",
       "0         False             21              30         True   \n",
       "1         False             42              41         True   \n",
       "\n",
       "                                             rowguid ModifiedDate  \n",
       "0  [74, 208, 225, 170, 55, 194, 116, 73, 180, 213...   2004-07-31  \n",
       "1  [64, 2, 72, 27, 192, 149, 15, 65, 167, 23, 235...   2004-07-31  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_dim_employee = \"SELECT * FROM adventureworks.employee\"\n",
    "df_dim_employee = get_mysql_dataframe(spark, sql_dim_employee, **mysql_args)\n",
    "df_dim_employee.show(2)\n",
    "df_dim_employee.write.saveAsTable(f\"{dest_database}.dim_employee\", mode=\"overwrite\")\n",
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_employee;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_employee LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb5fe21-f600-4a89-9b33-e9920fd96c60",
   "metadata": {},
   "source": [
    "### 1.3 Extract MySQL Query into jSON file for mongodb upload\n",
    "    - vendors (json) extracted to mongodb, then read back to spark from mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9908cf71-b91d-4ba4-8766-4b10611d1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_mongo_client(**mongodb_args)\n",
    "\n",
    "json_files = {\"vendors\" : \"dim_vendors.json\"}\n",
    "\n",
    "set_mongo_collections(client, mongodb_args[\"db_name\"], batch_dir, json_files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63bd866d-8fb8-43bb-9353-65133c4bbcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>AccountNumber</th>\n",
       "      <th>ActiveFlag</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>AddressType</th>\n",
       "      <th>City</th>\n",
       "      <th>CreditRating</th>\n",
       "      <th>Name</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>PreferredVendorStatus</th>\n",
       "      <th>StateProvinceCode</th>\n",
       "      <th>State_Province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>INTERNAT0001</td>\n",
       "      <td>1</td>\n",
       "      <td>683 Larch Ct.</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>1</td>\n",
       "      <td>International</td>\n",
       "      <td>84101</td>\n",
       "      <td>1</td>\n",
       "      <td>UT</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ELECTRON0002</td>\n",
       "      <td>1</td>\n",
       "      <td>8547 Catherine Way</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>1</td>\n",
       "      <td>Electronic Bike Repair &amp; Supplies</td>\n",
       "      <td>98403</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID AccountNumber ActiveFlag        AddressLine1  AddressType  \\\n",
       "0         1  INTERNAT0001          1       683 Larch Ct.  Main Office   \n",
       "1         2  ELECTRON0002          1  8547 Catherine Way  Main Office   \n",
       "\n",
       "             City  CreditRating                               Name PostalCode  \\\n",
       "0  Salt Lake City             1                      International      84101   \n",
       "1          Tacoma             1  Electronic Bike Repair & Supplies      98403   \n",
       "\n",
       "  PreferredVendorStatus StateProvinceCode State_Province  \n",
       "0                     1               UT            Utah  \n",
       "1                     1               WA      Washington  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongodb_args[\"collection\"] = \"vendors\"\n",
    "\n",
    "df_dim_vendors = get_mongodb_dataframe(spark, **mongodb_args)\n",
    "\n",
    "ordered_columns = ['VendorID', 'AccountNumber', 'ActiveFlag', 'AddressLine1', 'AddressType'\n",
    "                   , 'City', 'CreditRating', 'Name', 'PostalCode'\n",
    "                   , 'PreferredVendorStatus', 'StateProvinceCode', 'State_Province']\n",
    "df_dim_vendors = df_dim_vendors[ordered_columns]\n",
    "df_dim_vendors.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "359521da-7a0b-41db-9f6d-4973b5df7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_vendors.write.saveAsTable(f\"{dest_database}.dim_vendors\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e47e35ed-f991-4ea5-9df6-c8e31a20eb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|            VendorID|                 int|   NULL|\n",
      "|       AccountNumber|              string|   NULL|\n",
      "|          ActiveFlag|              string|   NULL|\n",
      "|        AddressLine1|              string|   NULL|\n",
      "|         AddressType|              string|   NULL|\n",
      "|                City|              string|   NULL|\n",
      "|        CreditRating|                 int|   NULL|\n",
      "|                Name|              string|   NULL|\n",
      "|          PostalCode|              string|   NULL|\n",
      "|PreferredVendorSt...|              string|   NULL|\n",
      "|   StateProvinceCode|              string|   NULL|\n",
      "|      State_Province|              string|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|  adventureworks_dlh|       |\n",
      "|               Table|         dim_vendors|       |\n",
      "|        Created Time|Wed May 07 17:55:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "|          Created By|         Spark 3.5.4|       |\n",
      "+--------------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>AccountNumber</th>\n",
       "      <th>ActiveFlag</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>AddressType</th>\n",
       "      <th>City</th>\n",
       "      <th>CreditRating</th>\n",
       "      <th>Name</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>PreferredVendorStatus</th>\n",
       "      <th>StateProvinceCode</th>\n",
       "      <th>State_Province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>INTERNAT0001</td>\n",
       "      <td>1</td>\n",
       "      <td>683 Larch Ct.</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>1</td>\n",
       "      <td>International</td>\n",
       "      <td>84101</td>\n",
       "      <td>1</td>\n",
       "      <td>UT</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ELECTRON0002</td>\n",
       "      <td>1</td>\n",
       "      <td>8547 Catherine Way</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>1</td>\n",
       "      <td>Electronic Bike Repair &amp; Supplies</td>\n",
       "      <td>98403</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID AccountNumber ActiveFlag        AddressLine1  AddressType  \\\n",
       "0         1  INTERNAT0001          1       683 Larch Ct.  Main Office   \n",
       "1         2  ELECTRON0002          1  8547 Catherine Way  Main Office   \n",
       "\n",
       "             City  CreditRating                               Name PostalCode  \\\n",
       "0  Salt Lake City             1                      International      84101   \n",
       "1          Tacoma             1  Electronic Bike Repair & Supplies      98403   \n",
       "\n",
       "  PreferredVendorStatus StateProvinceCode State_Province  \n",
       "0                     1               UT            Utah  \n",
       "1                     1               WA      Washington  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_vendors;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_vendors LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68757e5-bb30-4eec-9cf5-467dc90f5ba7",
   "metadata": {},
   "source": [
    "### 1.4 Extract CSV from local into pyspark\n",
    "- products (CSV) was locally extracted and read into pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e44df10b-3022-4bc4-895e-ddf7282a42e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tangb\\DS-2002-main\\Projects\\proj_data\\adventureworks\\batch\\dim_products.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Name</th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>MakeFlag</th>\n",
       "      <th>FinishedGoodsFlag</th>\n",
       "      <th>Color</th>\n",
       "      <th>SafetyStockLevel</th>\n",
       "      <th>ReorderPoint</th>\n",
       "      <th>StandardCost</th>\n",
       "      <th>ListPrice</th>\n",
       "      <th>...</th>\n",
       "      <th>DaysToManufacture</th>\n",
       "      <th>ProductLine</th>\n",
       "      <th>Class</th>\n",
       "      <th>Style</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ProductSubcategory</th>\n",
       "      <th>ProductModel</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>DiscontinuedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adjustable Race</td>\n",
       "      <td>AR-5381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bearing Ball</td>\n",
       "      <td>BA-8327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID             Name ProductNumber  MakeFlag  FinishedGoodsFlag  \\\n",
       "0          1  Adjustable Race       AR-5381         0                  0   \n",
       "1          2     Bearing Ball       BA-8327         0                  0   \n",
       "\n",
       "  Color  SafetyStockLevel  ReorderPoint  StandardCost  ListPrice  ...  \\\n",
       "0  NULL              1000           750           0.0        0.0  ...   \n",
       "1  NULL              1000           750           0.0        0.0  ...   \n",
       "\n",
       "  DaysToManufacture ProductLine Class Style  ProductCategory  \\\n",
       "0                 0        NULL  NULL  NULL             NULL   \n",
       "1                 0        NULL  NULL  NULL             NULL   \n",
       "\n",
       "  ProductSubcategory ProductModel SellStartDate SellEndDate DiscontinuedDate  \n",
       "0               NULL         NULL    1998-06-01        NULL             NULL  \n",
       "1               NULL         NULL    1998-06-01        NULL             NULL  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_csv = os.path.join(batch_dir, 'dim_products.csv')\n",
    "print(products_csv)\n",
    "\n",
    "df_dim_products = spark.read.format('csv').options(header='true', inferSchema='true').load(products_csv)\n",
    "df_dim_products.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5616868e-4946-4136-9739-030c03724b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_products.write.saveAsTable(f\"{dest_database}.dim_products\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c56233e7-eeac-4ebb-9c51-a5be7d4890b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|           ProductID|      int|   NULL|\n",
      "|                Name|   string|   NULL|\n",
      "|       ProductNumber|   string|   NULL|\n",
      "|            MakeFlag|      int|   NULL|\n",
      "|   FinishedGoodsFlag|      int|   NULL|\n",
      "|               Color|   string|   NULL|\n",
      "|    SafetyStockLevel|      int|   NULL|\n",
      "|        ReorderPoint|      int|   NULL|\n",
      "|        StandardCost|   double|   NULL|\n",
      "|           ListPrice|   double|   NULL|\n",
      "|                Size|   string|   NULL|\n",
      "| SizeUnitMeasureCode|   string|   NULL|\n",
      "|WeightUnitMeasure...|   string|   NULL|\n",
      "|              Weight|   string|   NULL|\n",
      "|   DaysToManufacture|      int|   NULL|\n",
      "|         ProductLine|   string|   NULL|\n",
      "|               Class|   string|   NULL|\n",
      "|               Style|   string|   NULL|\n",
      "|     ProductCategory|   string|   NULL|\n",
      "|  ProductSubcategory|   string|   NULL|\n",
      "+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Name</th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>MakeFlag</th>\n",
       "      <th>FinishedGoodsFlag</th>\n",
       "      <th>Color</th>\n",
       "      <th>SafetyStockLevel</th>\n",
       "      <th>ReorderPoint</th>\n",
       "      <th>StandardCost</th>\n",
       "      <th>ListPrice</th>\n",
       "      <th>...</th>\n",
       "      <th>DaysToManufacture</th>\n",
       "      <th>ProductLine</th>\n",
       "      <th>Class</th>\n",
       "      <th>Style</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ProductSubcategory</th>\n",
       "      <th>ProductModel</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>DiscontinuedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adjustable Race</td>\n",
       "      <td>AR-5381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bearing Ball</td>\n",
       "      <td>BA-8327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID             Name ProductNumber  MakeFlag  FinishedGoodsFlag  \\\n",
       "0          1  Adjustable Race       AR-5381         0                  0   \n",
       "1          2     Bearing Ball       BA-8327         0                  0   \n",
       "\n",
       "  Color  SafetyStockLevel  ReorderPoint  StandardCost  ListPrice  ...  \\\n",
       "0  NULL              1000           750           0.0        0.0  ...   \n",
       "1  NULL              1000           750           0.0        0.0  ...   \n",
       "\n",
       "  DaysToManufacture ProductLine Class Style  ProductCategory  \\\n",
       "0                 0        NULL  NULL  NULL             NULL   \n",
       "1                 0        NULL  NULL  NULL             NULL   \n",
       "\n",
       "  ProductSubcategory ProductModel SellStartDate SellEndDate DiscontinuedDate  \n",
       "0               NULL         NULL    1998-06-01        NULL             NULL  \n",
       "1               NULL         NULL    1998-06-01        NULL             NULL  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_products;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_products LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deba5b6-dce1-4821-b1d6-098533b4524d",
   "metadata": {},
   "source": [
    "### 1.5 add surgate primary key for each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "964bbe42-f638-4819-acf9-f5c59a3cd00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Name</th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>MakeFlag</th>\n",
       "      <th>FinishedGoodsFlag</th>\n",
       "      <th>Color</th>\n",
       "      <th>SafetyStockLevel</th>\n",
       "      <th>ReorderPoint</th>\n",
       "      <th>StandardCost</th>\n",
       "      <th>...</th>\n",
       "      <th>DaysToManufacture</th>\n",
       "      <th>ProductLine</th>\n",
       "      <th>Class</th>\n",
       "      <th>Style</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ProductSubcategory</th>\n",
       "      <th>ProductModel</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>DiscontinuedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>LL Crankarm</td>\n",
       "      <td>CA-5965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Black</td>\n",
       "      <td>500</td>\n",
       "      <td>375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>L</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>343</td>\n",
       "      <td>Flat Washer 2</td>\n",
       "      <td>FW-1400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductKey  ProductID           Name ProductNumber  MakeFlag  \\\n",
       "0           1        317    LL Crankarm       CA-5965         0   \n",
       "1           1        343  Flat Washer 2       FW-1400         0   \n",
       "\n",
       "   FinishedGoodsFlag  Color  SafetyStockLevel  ReorderPoint  StandardCost  \\\n",
       "0                  0  Black               500           375           0.0   \n",
       "1                  0   NULL              1000           750           0.0   \n",
       "\n",
       "   ...  DaysToManufacture ProductLine Class Style ProductCategory  \\\n",
       "0  ...                  0        NULL    L   NULL            NULL   \n",
       "1  ...                  0        NULL  NULL  NULL            NULL   \n",
       "\n",
       "   ProductSubcategory ProductModel SellStartDate SellEndDate DiscontinuedDate  \n",
       "0                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "1                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dim_products.createOrReplaceTempView(\"products\")\n",
    "sql_products = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (PARTITION BY ProductID ORDER BY ProductID) AS ProductKey\n",
    "    FROM products;\n",
    "\"\"\"\n",
    "df_dim_products = spark.sql(sql_products)\n",
    "\n",
    "cols = df_dim_products.columns\n",
    "\n",
    "# Move 'ProductKey' to the front\n",
    "reordered_cols = ['ProductKey'] + [col for col in cols if col != 'ProductKey']\n",
    "\n",
    "# Apply the new column order\n",
    "df_dim_products = df_dim_products.select(reordered_cols)\n",
    "\n",
    "df_dim_products.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8ce418d-23aa-49b8-ae52-7c910f385a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp columns: ['BirthDate', 'HireDate', 'ModifiedDate']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeKey</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>NationalIDNumber</th>\n",
       "      <th>ContactID</th>\n",
       "      <th>LoginID</th>\n",
       "      <th>ManagerID</th>\n",
       "      <th>Title</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HireDate</th>\n",
       "      <th>SalariedFlag</th>\n",
       "      <th>VacationHours</th>\n",
       "      <th>SickLeaveHours</th>\n",
       "      <th>CurrentFlag</th>\n",
       "      <th>rowguid</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14417807</td>\n",
       "      <td>1209</td>\n",
       "      <td>adventure-works\\guy1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Production Technician - WC60</td>\n",
       "      <td>1972-05-15 00:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1996-07-31 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>[74, 208, 225, 170, 55, 194, 116, 73, 180, 213...</td>\n",
       "      <td>2004-07-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>253022876</td>\n",
       "      <td>1030</td>\n",
       "      <td>adventure-works\\kevin0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Marketing Assistant</td>\n",
       "      <td>1977-06-03 00:00:00</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>1997-02-26 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>True</td>\n",
       "      <td>[64, 2, 72, 27, 192, 149, 15, 65, 167, 23, 235...</td>\n",
       "      <td>2004-07-31 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeKey  EmployeeID NationalIDNumber  ContactID  \\\n",
       "0            1           1         14417807       1209   \n",
       "1            2           2        253022876       1030   \n",
       "\n",
       "                  LoginID  ManagerID                         Title  \\\n",
       "0    adventure-works\\guy1       16.0  Production Technician - WC60   \n",
       "1  adventure-works\\kevin0        6.0           Marketing Assistant   \n",
       "\n",
       "             BirthDate MaritalStatus Gender             HireDate  \\\n",
       "0  1972-05-15 00:00:00             M      M  1996-07-31 00:00:00   \n",
       "1  1977-06-03 00:00:00             S      M  1997-02-26 00:00:00   \n",
       "\n",
       "   SalariedFlag  VacationHours  SickLeaveHours  CurrentFlag  \\\n",
       "0         False             21              30         True   \n",
       "1         False             42              41         True   \n",
       "\n",
       "                                             rowguid         ModifiedDate  \n",
       "0  [74, 208, 225, 170, 55, 194, 116, 73, 180, 213...  2004-07-31 00:00:00  \n",
       "1  [64, 2, 72, 27, 192, 149, 15, 65, 167, 23, 235...  2004-07-31 00:00:00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dim_employee.createOrReplaceTempView(\"employees\")\n",
    "sql_employees = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (ORDER BY EmployeeId) AS EmployeeKey\n",
    "    FROM employees\n",
    "\"\"\"\n",
    "df_dim_employee = spark.sql(sql_employees)\n",
    "\n",
    "cols = df_dim_employee.columns\n",
    "reordered_cols = ['EmployeeKey'] + [col for col in cols if col != 'EmployeeKey']\n",
    "df_dim_employee = df_dim_employee.select(reordered_cols)\n",
    "\n",
    "# Option 1: Drop problematic timestamp columns\n",
    "# Identify TimestampType columns in df_dim_employee\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "timestamp_cols = [f.name for f in df_dim_employee.schema.fields if isinstance(f.dataType, TimestampType)]\n",
    "print(\"Timestamp columns:\", timestamp_cols)\n",
    "\n",
    "df_dim_employee_cleaned = df_dim_employee.drop(*timestamp_cols)\n",
    "\n",
    "# Option 2: Cast timestamp columns to string instead\n",
    "from pyspark.sql.functions import col\n",
    "for ts_col in timestamp_cols:\n",
    "    df_dim_employee = df_dim_employee.withColumn(ts_col, col(ts_col).cast(\"string\"))\n",
    "df_dim_employee.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94c63187-2f13-4026-a63c-d6d988c39947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorKey</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>AccountNumber</th>\n",
       "      <th>ActiveFlag</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>AddressType</th>\n",
       "      <th>City</th>\n",
       "      <th>CreditRating</th>\n",
       "      <th>Name</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>PreferredVendorStatus</th>\n",
       "      <th>StateProvinceCode</th>\n",
       "      <th>State_Province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>INTERNAT0001</td>\n",
       "      <td>1</td>\n",
       "      <td>683 Larch Ct.</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>1</td>\n",
       "      <td>International</td>\n",
       "      <td>84101</td>\n",
       "      <td>1</td>\n",
       "      <td>UT</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ELECTRON0002</td>\n",
       "      <td>1</td>\n",
       "      <td>8547 Catherine Way</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>1</td>\n",
       "      <td>Electronic Bike Repair &amp; Supplies</td>\n",
       "      <td>98403</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorKey  VendorID AccountNumber ActiveFlag        AddressLine1  \\\n",
       "0          1         1  INTERNAT0001          1       683 Larch Ct.   \n",
       "1          2         2  ELECTRON0002          1  8547 Catherine Way   \n",
       "\n",
       "   AddressType            City  CreditRating  \\\n",
       "0  Main Office  Salt Lake City             1   \n",
       "1  Main Office          Tacoma             1   \n",
       "\n",
       "                                Name PostalCode PreferredVendorStatus  \\\n",
       "0                      International      84101                     1   \n",
       "1  Electronic Bike Repair & Supplies      98403                     1   \n",
       "\n",
       "  StateProvinceCode State_Province  \n",
       "0               UT            Utah  \n",
       "1               WA      Washington  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dim_vendors.createOrReplaceTempView(\"vendors\")\n",
    "sql_vendors = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (ORDER BY VendorId) AS VendorKey\n",
    "    FROM vendors\n",
    "\"\"\"\n",
    "df_dim_vendors = spark.sql(sql_vendors)\n",
    "\n",
    "cols = df_dim_vendors.columns\n",
    "reordered_cols = ['VendorKey'] + [col for col in cols if col != 'VendorKey']\n",
    "df_dim_vendors = df_dim_vendors.select(reordered_cols)\n",
    "df_dim_vendors.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af63b8-6aba-4bfc-b56d-b9b3296697d3",
   "metadata": {},
   "source": [
    "### 1.5 Verify that pyspark as all tables\n",
    "- df_dim_date\n",
    "- df_dim_employee\n",
    "- df_dim_vendors\n",
    "- df_dim_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf644225-0181-4afa-add5-5159d0e8e495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adventureworks_dlh</td>\n",
       "      <td>dim_date</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adventureworks_dlh</td>\n",
       "      <td>dim_employee</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adventureworks_dlh</td>\n",
       "      <td>dim_products</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adventureworks_dlh</td>\n",
       "      <td>dim_vendors</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>employees</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>products</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>vendors</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            namespace     tableName  isTemporary\n",
       "0  adventureworks_dlh      dim_date        False\n",
       "1  adventureworks_dlh  dim_employee        False\n",
       "2  adventureworks_dlh  dim_products        False\n",
       "3  adventureworks_dlh   dim_vendors        False\n",
       "4                         employees         True\n",
       "5                          products         True\n",
       "6                           vendors         True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"USE {dest_database};\")\n",
    "spark.sql(\"SHOW TABLES\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c825e675-1d12-436d-a3eb-bf26dc17b9eb",
   "metadata": {},
   "source": [
    "### 2.0 Pyspark streaming with fact_orders\n",
    "#### 2.1 Verify the location of the source data files on the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd37ceb2-9f93-474d-af0e-21308ca50032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>modification_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adventureworks_fact_orders_1.json</td>\n",
       "      <td>1041129</td>\n",
       "      <td>2025-05-02 23:28:32.406136036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adventureworks_fact_orders_2.json</td>\n",
       "      <td>1049473</td>\n",
       "      <td>2025-05-02 23:28:32.422135115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adventureworks_fact_orders_3.json</td>\n",
       "      <td>1045456</td>\n",
       "      <td>2025-05-02 23:28:32.433131218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name     size             modification_time\n",
       "0  adventureworks_fact_orders_1.json  1041129 2025-05-02 23:28:32.406136036\n",
       "1  adventureworks_fact_orders_2.json  1049473 2025-05-02 23:28:32.422135115\n",
       "2  adventureworks_fact_orders_3.json  1045456 2025-05-02 23:28:32.433131218"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_info(fact_orders_stream_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31397988-047e-4ddd-b970-cfc2ef8705ad",
   "metadata": {},
   "source": [
    "#### 2.2 Create the Bronze Layer: Stage <span style=\"color:darkred\">Fact Orders table</span> Data\n",
    "##### 2.2.1 read in json file into stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1566b920-3c1d-47f0-bbb1-0017a59df734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_orders_bronze = (\n",
    "    spark.readStream \\\n",
    "    .option(\"schemaLocation\", fact_orders_output_bronze) \\\n",
    "    .option(\"maxFilesPerTrigger\", 1) \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .json(fact_orders_stream_dir)\n",
    ")\n",
    "\n",
    "df_fact_orders_bronze.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca1516-c11d-4c84-9c31-742af7ba55de",
   "metadata": {},
   "source": [
    "##### 3.2.2. Write the Streaming Data to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffd5bfce-73ae-408f-9370-ba913364ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_orders_checkpoint_bronze = os.path.join(fact_orders_output_bronze, '_checkpoint')\n",
    "\n",
    "fact_orders_bronze_query = (\n",
    "    df_fact_orders_bronze\n",
    "    # Add Current Timestamp and Input Filename columns for Traceability\n",
    "    .withColumn(\"receipt_time\", current_timestamp())\n",
    "    .withColumn(\"source_file\", input_file_name())\n",
    "    \n",
    "    .writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .queryName(\"fact_orders_bronze\")\n",
    "    .trigger(availableNow = True) \\\n",
    "    .option(\"checkpointLocation\", fact_orders_checkpoint_bronze) \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .start(fact_orders_output_bronze)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca92b65b-3104-4672-8f70-cf53c1bdddce",
   "metadata": {},
   "source": [
    "##### 2.2.3. Unit Test: Implement Query Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5255c971-488c-4e9b-9df7-2925b74dadde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 72a64501-e85b-4437-8d34-57c79a798ff2\n",
      "Query Name: fact_orders_bronze\n",
      "Query Status: {'message': 'Initializing sources', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query ID: {fact_orders_bronze_query.id}\")\n",
    "print(f\"Query Name: {fact_orders_bronze_query.name}\")\n",
    "print(f\"Query Status: {fact_orders_bronze_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "063788c2-e656-4bc4-8e7d-27e93343527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_orders_bronze_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa9137-60c6-4c47-a782-0307e5e3fdb1",
   "metadata": {},
   "source": [
    "#### 2.3. Create the Silver Layer: Integrate \"Cold-path\" Data & Make Transformations\n",
    "##### 2.3.1. Prepare Role-Playing Dimension Primary and Business Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5fc640e-0bed-44c2-b069-9eb5ccab17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_order_date = df_dim_date.select(col(\"date_key\").alias(\"order_date_key\"), col(\"full_date\").alias(\"fact_order_full_date\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93c5ba36-dc88-47c3-9fa2-71079efb7554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DueDate: long (nullable = true)\n",
      " |-- EmployeeID: long (nullable = true)\n",
      " |-- Freight: double (nullable = true)\n",
      " |-- LineTotal: double (nullable = true)\n",
      " |-- OrderDate: long (nullable = true)\n",
      " |-- OrderQty: long (nullable = true)\n",
      " |-- ProductID: long (nullable = true)\n",
      " |-- PurchaseOrderID: long (nullable = true)\n",
      " |-- ReceivedQty: double (nullable = true)\n",
      " |-- ShipDate: long (nullable = true)\n",
      " |-- Status: long (nullable = true)\n",
      " |-- StockedQty: double (nullable = true)\n",
      " |-- SubTotal: double (nullable = true)\n",
      " |-- TaxAmt: double (nullable = true)\n",
      " |-- TotalDue: double (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- fact_purchase_orders_key: long (nullable = true)\n",
      " |-- receipt_time: timestamp (nullable = true)\n",
      " |-- source_file: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.readStream.format(\"parquet\").load(fact_orders_output_bronze).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2985206-f2e4-49c3-bbff-ba3a74939e79",
   "metadata": {},
   "source": [
    "##### 2.3.2. Define Silver Query to Join Streaming with Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4555e004-567e-42d8-8724-d2fa548e4fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x1506d4c5f40>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import LongType\n",
    "\n",
    "# Load the bronze data (without CustomerID, as you've removed it)\n",
    "df_bronze = spark.readStream.format(\"parquet\").load(fact_orders_output_bronze)\n",
    "\n",
    "# Perform the necessary joins\n",
    "df_fact_orders_silver = df_bronze \\\n",
    "    .join(df_dim_employee, \"EmployeeID\") \\\n",
    "    .join(df_dim_products, \"ProductID\") \\\n",
    "    .join(df_dim_vendors, \"VendorID\") \\\n",
    "    .select(\n",
    "        df_dim_employee.EmployeeKey.cast(LongType()).alias(\"EmployeeKey\"),\n",
    "        df_dim_products.ProductKey.cast(LongType()).alias(\"ProductKey\"),\n",
    "        df_dim_vendors.VendorKey.cast(LongType()).alias(\"VendorKey\"),\n",
    "        df_bronze.DueDate,\n",
    "        df_bronze.Freight,\n",
    "        df_bronze.LineTotal,\n",
    "        df_bronze.OrderDate,\n",
    "        df_bronze.OrderQty,\n",
    "        df_bronze.ReceivedQty,\n",
    "        df_bronze.ShipDate,\n",
    "        df_bronze.Status,\n",
    "        df_bronze.StockedQty,\n",
    "        df_bronze.ShipDate,\n",
    "        df_bronze.Status,\n",
    "        df_bronze.TotalDue,\n",
    "        df_bronze.UnitPrice\n",
    "    )\n",
    "\n",
    "# Define the streaming output path for the silver layer\n",
    "df_fact_orders_silver.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", \"path/to/checkpoint/dir\") \\\n",
    "    .start(\"path/to/output/dir\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e05f7d3a-eb9d-4139-b7d3-c53c56ecf0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_orders_silver.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d0388d0-d714-428c-a1c6-582089b6297d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EmployeeKey: long (nullable = false)\n",
      " |-- ProductKey: long (nullable = false)\n",
      " |-- VendorKey: long (nullable = false)\n",
      " |-- DueDate: long (nullable = true)\n",
      " |-- Freight: double (nullable = true)\n",
      " |-- LineTotal: double (nullable = true)\n",
      " |-- OrderDate: long (nullable = true)\n",
      " |-- OrderQty: long (nullable = true)\n",
      " |-- ReceivedQty: double (nullable = true)\n",
      " |-- ShipDate: long (nullable = true)\n",
      " |-- Status: long (nullable = true)\n",
      " |-- StockedQty: double (nullable = true)\n",
      " |-- ShipDate: long (nullable = true)\n",
      " |-- Status: long (nullable = true)\n",
      " |-- TotalDue: double (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fact_orders_silver.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c8053-b896-4218-8f4c-6fadb007cbb3",
   "metadata": {},
   "source": [
    "##### 2.3.3. Write the Transformed Streaming data to the Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "780035ba-86fe-4d89-a011-912ddd4a051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_orders_checkpoint_silver = os.path.join(fact_orders_output_silver, '_checkpoint')\n",
    "\n",
    "fact_orders_silver_query = (\n",
    "    df_fact_orders_silver.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .queryName(\"orders_silver\")\n",
    "    .trigger(availableNow = True) \\\n",
    "    .option(\"checkpointLocation\", fact_orders_checkpoint_silver) \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .start(fact_orders_output_silver)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e303e6-6833-433c-8630-49f96138a50b",
   "metadata": {},
   "source": [
    "##### 2.3.4. Unit Test: Implement Query Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30d90240-d16c-47de-9339-1391371c92c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 20d6a4f3-7146-4dd4-b8f7-d64842ce9eac\n",
      "Query Name: orders_silver\n",
      "Query Status: {'message': 'Initializing sources', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query ID: {fact_orders_silver_query.id}\")\n",
    "print(f\"Query Name: {fact_orders_silver_query.name}\")\n",
    "print(f\"Query Status: {fact_orders_silver_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22029a7d-ffdd-489d-a356-f31f6b3b236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_orders_silver_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5615345c-e9b7-4b2b-bad8-50f9d9c4f2fa",
   "metadata": {},
   "source": [
    "#### 2.4. Create Gold Layer: Perform Aggregations\n",
    "##### 2.4.1. Define a Query to Create a Business Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53a44c5d-b76c-4e88-9bb7-687ce6739d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Name</th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>MakeFlag</th>\n",
       "      <th>FinishedGoodsFlag</th>\n",
       "      <th>Color</th>\n",
       "      <th>SafetyStockLevel</th>\n",
       "      <th>ReorderPoint</th>\n",
       "      <th>StandardCost</th>\n",
       "      <th>...</th>\n",
       "      <th>DaysToManufacture</th>\n",
       "      <th>ProductLine</th>\n",
       "      <th>Class</th>\n",
       "      <th>Style</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ProductSubcategory</th>\n",
       "      <th>ProductModel</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>DiscontinuedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>LL Crankarm</td>\n",
       "      <td>CA-5965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Black</td>\n",
       "      <td>500</td>\n",
       "      <td>375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>L</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>343</td>\n",
       "      <td>Flat Washer 2</td>\n",
       "      <td>FW-1400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>412</td>\n",
       "      <td>Internal Lock Washer 3</td>\n",
       "      <td>LI-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>434</td>\n",
       "      <td>Thin-Jam Lock Nut 7</td>\n",
       "      <td>LJ-7161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>Lock Nut 6</td>\n",
       "      <td>LN-1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>443</td>\n",
       "      <td>Lock Nut 8</td>\n",
       "      <td>LN-1420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>452</td>\n",
       "      <td>Lock Nut 2</td>\n",
       "      <td>LN-5400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>471</td>\n",
       "      <td>Lock Washer 12</td>\n",
       "      <td>LW-5800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>475</td>\n",
       "      <td>Lock Washer 11</td>\n",
       "      <td>LW-9160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>496</td>\n",
       "      <td>Paint - Yellow</td>\n",
       "      <td>PA-823Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductKey  ProductID                    Name ProductNumber  MakeFlag  \\\n",
       "0           1        317             LL Crankarm       CA-5965         0   \n",
       "1           1        343           Flat Washer 2       FW-1400         0   \n",
       "2           1        412  Internal Lock Washer 3       LI-1000         0   \n",
       "3           1        434     Thin-Jam Lock Nut 7       LJ-7161         0   \n",
       "4           1        439              Lock Nut 6       LN-1032         0   \n",
       "5           1        443              Lock Nut 8       LN-1420         0   \n",
       "6           1        452              Lock Nut 2       LN-5400         0   \n",
       "7           1        471          Lock Washer 12       LW-5800         0   \n",
       "8           1        475          Lock Washer 11       LW-9160         0   \n",
       "9           1        496          Paint - Yellow       PA-823Y         0   \n",
       "\n",
       "   FinishedGoodsFlag  Color  SafetyStockLevel  ReorderPoint  StandardCost  \\\n",
       "0                  0  Black               500           375           0.0   \n",
       "1                  0   NULL              1000           750           0.0   \n",
       "2                  0   NULL              1000           750           0.0   \n",
       "3                  0   NULL              1000           750           0.0   \n",
       "4                  0   NULL              1000           750           0.0   \n",
       "5                  0   NULL              1000           750           0.0   \n",
       "6                  0   NULL              1000           750           0.0   \n",
       "7                  0   NULL              1000           750           0.0   \n",
       "8                  0   NULL              1000           750           0.0   \n",
       "9                  0   NULL                60            45           0.0   \n",
       "\n",
       "   ...  DaysToManufacture ProductLine Class Style ProductCategory  \\\n",
       "0  ...                  0        NULL    L   NULL            NULL   \n",
       "1  ...                  0        NULL  NULL  NULL            NULL   \n",
       "2  ...                  0        NULL  NULL  NULL            NULL   \n",
       "3  ...                  0        NULL  NULL  NULL            NULL   \n",
       "4  ...                  0        NULL  NULL  NULL            NULL   \n",
       "5  ...                  0        NULL  NULL  NULL            NULL   \n",
       "6  ...                  0        NULL  NULL  NULL            NULL   \n",
       "7  ...                  0        NULL  NULL  NULL            NULL   \n",
       "8  ...                  0        NULL  NULL  NULL            NULL   \n",
       "9  ...                  0        NULL  NULL  NULL            NULL   \n",
       "\n",
       "   ProductSubcategory ProductModel SellStartDate SellEndDate DiscontinuedDate  \n",
       "0                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "1                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "2                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "3                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "4                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "5                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "6                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "7                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "8                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "9                NULL         NULL    1998-06-01        NULL             NULL  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dim_products.toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67727bbc-9b94-4137-bc1d-ad71ba99ca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_key: integer (nullable = true)\n",
      " |-- full_date: date (nullable = true)\n",
      " |-- month_of_year: integer (nullable = true)\n",
      " |-- month_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month, date_format\n",
    "\n",
    "df_dim_date = df_dim_date \\\n",
    "    .withColumn(\"month_of_year\", month(\"full_date\")) \\\n",
    "    .withColumn(\"month_name\", date_format(\"full_date\", \"MMMM\"))\n",
    "df_dim_date.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6b5843c-8500-476a-8218-6bbbfb8b19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, asc, desc, to_date\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Convert OrderDate (assumed to be long or timestamp) to a comparable format (e.g., date)\n",
    "df_fact_orders_by_product_category_gold = (\n",
    "    spark.readStream.format(\"parquet\").load(fact_orders_output_silver)\n",
    "    .withColumn(\"order_date_parsed\", to_date(col(\"OrderDate\").cast(\"timestamp\")))  # Parse OrderDate\n",
    "    .join(df_dim_products, \"ProductKey\")\n",
    "    .join(\n",
    "        df_dim_date,\n",
    "        df_dim_date.full_date == col(\"order_date_parsed\")  # Adjust \"full_date\" to your actual column name\n",
    "    )\n",
    "    .groupBy(\"month_of_year\", \"Name\", \"month_name\")\n",
    "    .agg(count(\"StandardCost\").alias(\"Standard Cost\"))\n",
    "    .orderBy(asc(\"month_of_year\"), desc(\"Standard Cost\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f437083a-2775-4b63-9729-771aebc2c03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month_of_year: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- month_name: string (nullable = true)\n",
      " |-- Standard Cost: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fact_orders_by_product_category_gold.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c330647-9787-4ac5-9906-ba947665072f",
   "metadata": {},
   "source": [
    "##### 3.4.2. Write the Streaming data to a Parquet File in \"Complete\" mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d24c72bf-caef-4697-a29f-a1f35b10519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_orders_gold_query = (\n",
    "    df_fact_orders_by_product_category_gold.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .queryName(\"fact_orders_by_product_category\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78ce592a-6e66-4dcd-a39d-c9a0e163c980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ProductKey: integer (nullable = false)\n",
      " |-- ProductID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- ProductNumber: string (nullable = true)\n",
      " |-- MakeFlag: integer (nullable = true)\n",
      " |-- FinishedGoodsFlag: integer (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- SafetyStockLevel: integer (nullable = true)\n",
      " |-- ReorderPoint: integer (nullable = true)\n",
      " |-- StandardCost: double (nullable = true)\n",
      " |-- ListPrice: double (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      " |-- SizeUnitMeasureCode: string (nullable = true)\n",
      " |-- WeightUnitMeasureCode: string (nullable = true)\n",
      " |-- Weight: string (nullable = true)\n",
      " |-- DaysToManufacture: integer (nullable = true)\n",
      " |-- ProductLine: string (nullable = true)\n",
      " |-- Class: string (nullable = true)\n",
      " |-- Style: string (nullable = true)\n",
      " |-- ProductCategory: string (nullable = true)\n",
      " |-- ProductSubcategory: string (nullable = true)\n",
      " |-- ProductModel: string (nullable = true)\n",
      " |-- SellStartDate: timestamp (nullable = true)\n",
      " |-- SellEndDate: string (nullable = true)\n",
      " |-- DiscontinuedDate: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dim_products.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89dcb509-8dbe-427b-a5cc-389fc12bd512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month_of_year: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- month_name: string (nullable = true)\n",
      " |-- Standard Cost: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fact_orders_by_product_category = spark.sql(\"SELECT * FROM fact_orders_by_product_category\")\n",
    "df_fact_orders_by_product_category.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b8b95d0-d9f9-4c7e-85d9-516730dfe7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_orders_by_product_category_gold_final = df_fact_orders_by_product_category \\\n",
    ".select(col(\"month_name\").alias(\"Month\"), \\\n",
    "        col(\"Name\").alias(\"Product Name\"), \\\n",
    "        col(\"Standard Cost\").alias(\"Standard Cost\")) \\\n",
    ".orderBy(asc(\"month_of_year\"), desc(\"Standard Cost\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe2ca084-8b58-4bd0-8518-9a3789cf8759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Standard Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Month, Product Name, Standard Cost]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_orders_by_product_category_gold_final.write.saveAsTable(f\"{dest_database}.fact_orders_by_product_category\", mode=\"overwrite\")\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.fact_orders_by_product_category\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b8c152d-479e-45a3-96dc-d93ad2c83a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd0258-cb88-43fd-a0b0-814398786559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (pysparkenv)",
   "language": "python",
   "name": "pysparkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
